{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络CNN - 莫烦pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 卷积神经网络处理MINST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision #包括了一些数据库\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8116bc1be4a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#是否是训练数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#原始数据转换为tensor格式，从图片的(0,255)压缩到(0,1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdownload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDOWNLOAD_MNIST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#如果已经下载好了数据，则设置为False不再重复下载\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fedml\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             raise RuntimeError('Dataset not found.' +\n\u001b[0m\u001b[0;32m     83\u001b[0m                                ' You can use download=True to download it')\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ],
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error"
    }
   ],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001\n",
    "DOWNLOAD_MNIST = False\n",
    "\n",
    "# MINST数据下载（训练数据）\n",
    "train_data = torchvision.datasets.MNIST( #去MINST网站下载\n",
    "    root = './minist',\n",
    "    train = True, #是否是训练数据\n",
    "    transform = torchvision.transforms.ToTensor(), #原始数据转换为tensor格式，从图片的(0,255)压缩到(0,1)\n",
    "    download=DOWNLOAD_MNIST, #如果已经下载好了数据，则设置为False不再重复下载\n",
    ")\n",
    "\n",
    "print(train_data.train_data.size()) # (60000, 28, 28)\n",
    "print(train_data.train_labels.size()) # (60000)\n",
    "# 画图显示数据（此处只显示第一张图片）\n",
    "plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 数据装载到Data Loader中得到mini-batch training, the image batch shape will be (50, 1, 28, 28)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# MINST数据下载（测试数据）\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root = './mnist',\n",
    "    train = False, #不是训练数据，是测试数据\n",
    "    download = True\n",
    ")\n",
    "test_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)[:2000]/255 #shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\n",
    "test_y = test_data.test_labels[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 积(Conv2d) -> 激励函数(ReLU) -> 池化, 向下采样 (MaxPooling) -> 再来一遍 -> 展平多维的卷积成的特征图 -> 接入全连接层 (Linear) -> 输出\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential( #卷积层，使用Sequential定义（和快速定义神经网络一样的操作）\n",
    "            # 此时图片(1, 28, 28)，分别表示高、长、宽，后两个是图片分辨率\n",
    "            nn.Conv2d(# 1.卷积层，过滤器（扫描器），长宽指明能够收集多大范围的信息，高度指有多少个filter用来提取出卷积出的特征属性（个数）\n",
    "                in_channels = 1,   #表示这张图片有多少个（高度）层的，如RGB有三个、灰度图片有一个\n",
    "                out_channels = 16, #输出的高度，就是filter（卷积核的个数），这16个同时在某个区域上扫描提取了16个不同的特征，然后把他们放在下一层\n",
    "                kernel_size = 5,   #filter的宽和高都是5个像素点，所以filter的维度5*5*16\n",
    "                stride = 1,        #步长，每次卷积核移动的像素大小\n",
    "                padding = 2,       #在边缘添加多少像素点(全0的)，为了不丢失边缘数据特征。 if stride=1, padding=(kernel_size-1)/2=(5-1)/2\n",
    "            ),  # -> (16, 28, 28)\n",
    "            nn.ReLU(), # 2.非线性激活层 -> (16, 28, 28)\n",
    "            nn.MaxPool2d(kernel_size = 2), # 3.池化层，筛选重要的信息。从更厚的数据中提取，也就是缩小长宽， -> (16, 14, 14)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential( #第二个卷积层\n",
    "            # 此时图片(16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2), #这一卷积层的in_channel是上一层的out_channel，->(32, 14, 14)\n",
    "            nn.ReLU(), # -> (32, 14, 14)\n",
    "            nn.MaxPool2d(2), # ->(32, 7, 7)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Linear(32 * 7 * 7, 10) #输出层，输入的是图片经过两层卷积后的特征(32,7,7)展平后的结果，输出的是0~9十个分类中的哪个\n",
    "        #Linear的第三个参数bias表示图层是否学习附加偏差\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x) #(batch, 32, 7, 7)\n",
    "        x = x.view(x.size(0), -1) #展平数据：(batch, 32*7*7)，保留size(0),-1表示后面维度的数据全部变到一起\n",
    "        output = self.out(x)\n",
    "        return output,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 训练过程，使用Adam优化\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # 交叉熵损失函数，the target label is not one-hotted\n",
    "\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):   # 分配batch data, normalize x when iterate train_loader\n",
    "        output = cnn(b_x)[0]               # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss, calculate the loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients, optimize params\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            test_output, last_layer = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)\n",
    "            \n",
    "# print 10 predictions from test data\n",
    "test_output, _ = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].numpy(), 'real number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}